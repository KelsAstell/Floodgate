import json
import os
import time
from config import *
from openapi.database import POOL_SIZE, pool, get_pending_counts, get_or_create_digit_id, get_dau_today
from openapi.network import get_send_failed_count, post_floodgate_message
from openapi.parse_open_event import get_global_message_id

from openapi.token_manage import token_manager


async def check_config():
    from config import BOT_SECRET, BOT_APPID, SANDBOX_CHANNEL_ID
    errors = []
    warnings = []
    os.makedirs("logs", exist_ok=True)
    log.add(
        os.path.join("logs", "{time:YYYY-MM-DD}.log"),
        level="WARNING",
        rotation="00:00",            # æ¯å¤© 00:00 åˆ†å‰²
        retention="7 days",          # ä¿ç•™ 7 å¤©
        encoding="utf-8",
        enqueue=True,                # å¤šçº¿ç¨‹/å¤šè¿›ç¨‹å®‰å…¨ï¼ˆæ¨èå¼€å¯ï¼‰
        backtrace=True,              # é”™è¯¯æ—¥å¿—ä¸­æ˜¾ç¤ºå®Œæ•´å †æ ˆ
        diagnose=True                # æ˜¾ç¤ºå˜é‡å€¼
    )
    if not isinstance(BOT_SECRET, str) or len(BOT_SECRET.strip()) == 0:
        errors.append("BOT_SECRET æœªå¡«å†™")
    if not isinstance(BOT_APPID, int) or BOT_APPID <= 0:
        errors.append("BOT_APPID å¿…é¡»ä¸ºæ­£æ•´æ•°")
    if not isinstance(SANDBOX_CHANNEL_ID, int):
        errors.append("SANDBOX_CHANNEL_ID å¿…é¡»ä¸ºæ•´æ•°")
    if SANDBOX_CHANNEL_ID == 0:
        warnings.append(
            "SANDBOX_CHANNEL_ID æœªå¡«ï¼Œä½¿ç”¨ /upload_image æ¥å£æ—¶éœ€è¦åœ¨è¯·æ±‚ä½“é‡Œæä¾› channel_idï¼Œæˆ–å¡«å†™é…ç½®ä¸­çš„ SANDBOX_CHANNEL_ID")
    if errors:
        for error in errors:
            log.error(f"[é…ç½®é”™è¯¯] {error}")
        log.error(f"[é…ç½®é”™è¯¯] è¯·åœ¨config.pyä¸­å¡«å†™æ­£ç¡®ä¿¡æ¯åé‡è¯•ï¼")
        exit(1)
    log.success("å·²é€šè¿‡åŸºç¡€é…ç½®æ£€æŸ¥")
    return True

async def show_welcome():
    log.success("Floodgate Endpointsï¼š")
    base_url = f"http://127.0.0.1:{PORT}"
    log.success(f"{base_url}{WEBHOOK_ENDPOINT}")
    log.success(f"{base_url}{WS_ENDPOINT}")
    log.success(f"{base_url}{WEBHOOK_ENDPOINT}/health")
    log.success(f"{base_url}/avatar")
    log.success(f"{base_url}/user_stats")
    log.success(f"{base_url}/upload_image")
    log.success(f"{base_url}/docs")
    log.success("Repo: https://github.com/KelsAstell/Floodgate")




async def get_health(start_time, connected_clients):
    from openapi.network import msg_seq_cache
    now = time.time()
    uptime_sec = int(now - start_time)
    if uptime_sec >= 86400:
        days, remainder = divmod(uptime_sec, 86400)
        hours, remainder = divmod(remainder, 3600)
        minutes, seconds = divmod(remainder, 60)
        uptime_str = f"{days}d {hours}h {minutes}m {seconds}s"
    else:
        hours, remainder = divmod(uptime_sec, 3600)
        minutes, seconds = divmod(remainder, 60)
        uptime_str = f"{hours}h {minutes}m {seconds}s"
    try:
        token_remain = await token_manager.remaining_seconds()
    except Exception as e:
        log.warning(f"Token å‰©ä½™æ—¶é—´è®¡ç®—å¤±è´¥: {e}")
        token_remain = None
    dau_dict = await get_dau_today()
    return {
        "status": "ok",
        "env": 'sandbox' if SANDBOX_MODE else 'production',
        "version": VERSION,  # ç‰ˆæœ¬å·
        "repo": "https://github.com/KelsAstell/Floodgate",
        "uptime": uptime_str,  # è¿è¡Œæ—¶é—´
        "clients": len(connected_clients),  # å½“å‰wså®¢æˆ·ç«¯æ•°
        "access_token": {  # access_token çŠ¶æ€
            "valid": await token_manager.get_access_token(only_get_token=True) is not None,
            "remain_seconds": token_remain
        },
        "database": {  # æ•°æ®åº“çŠ¶æ€
            "pool_size": POOL_SIZE,
            "queue": pool._queue.qsize() if pool._queue else 0
        },
        "cache": {
            "message": {  # æ¶ˆæ¯ç¼“å­˜çŠ¶æ€
                "seq_cache_size": len(msg_seq_cache),
                "seq_cache_size_max": SEQ_CACHE_SIZE,
            },
            "usage": {
                "flush_size": await get_pending_counts()
            }
        },
        "endpoints": {  # æ¥å£åœ°å€
            "websocket": WS_ENDPOINT,
            "webhook": WEBHOOK_ENDPOINT
        },
        "transparent": TRANSPARENT_OPENID,
        "dau":dau_dict.get("dau",0),
        "dai":dau_dict.get("dai",0),
        "current_msgid": await get_global_message_id(),
        "send_failed": await get_send_failed_count()
    }


TEMP_MAINTAINING_MESSAGE = None


async def get_maintaining_message():
    return TEMP_MAINTAINING_MESSAGE or MAINTAINING_MESSAGE


async def set_maintaining_message(message):
    global TEMP_MAINTAINING_MESSAGE
    TEMP_MAINTAINING_MESSAGE = message

async def is_user_admin(d):
    user_id = d.get("author", {}).get("union_openid") if TRANSPARENT_OPENID else await get_or_create_digit_id(d.get("author", {}).get("union_openid"))
    return user_id in ADMIN_LIST

from collections import defaultdict, deque
from datetime import datetime, timedelta, date

user_message_history = defaultdict(deque)
temp_ban_until = {}  # uid -> è§£å°æ—¶é—´

async def rate_limit(d):
    uid = d.get("author", {}).get("union_openid")
    # è‡ªå·±äººï¼Œç®¡ç†å‘˜ä¸é™é€Ÿ
    if await is_user_admin(d):
        return False
    now = datetime.now()
    # æ£€æŸ¥æ˜¯å¦è¢«ä¸´æ—¶å°ç¦
    if uid in temp_ban_until and now < temp_ban_until[uid]:
        log.warning(f"{uid}({await get_or_create_digit_id(uid)})å‘é€é¢‘ç‡è¿‡é«˜ï¼Œä¸´æ—¶å°ç¦è‡³ {temp_ban_until[uid]}")
        await post_floodgate_message(f"ğŸ§Šä½ å‘é€å¾—å¤ªå¿«å•¦ï¼Œè¯· {int((temp_ban_until[uid] - now).total_seconds())} ç§’åå†è¯•uwu~", d)
        return True
    elif uid in temp_ban_until:
        del temp_ban_until[uid]
    msg_times = user_message_history[uid]
    msg_times.append(now)
    while msg_times and (now - msg_times[0]).total_seconds() > TIME_WINDOW_SECONDS:
        msg_times.popleft()
    if len(msg_times) > MAX_MESSAGES:
        temp_ban_until[uid] = now + timedelta(seconds=BLOCK_DURATION_SECONDS)
        await post_floodgate_message(f"ğŸ§Šä½ å‘é€å¾—å¤ªå¿«å•¦ï¼Œè¯· {BLOCK_DURATION_SECONDS} ç§’åå†è¯•uwu~", d)
        return True
    return False

async def get_dau_history():
    if not os.path.exists(STAT_LOG):
        return "æ— å†å²ç»Ÿè®¡æ•°æ®"

    # è¯»å– JSON æ–‡ä»¶
    with open(STAT_LOG, 'r', encoding='utf-8') as f:
        data = json.load(f)

    today = date.today()
    lines = []
    # æŒ‰é¡ºåºéå†æ‰€æœ‰å¤©æ•°ï¼ˆæœ€æ—§åˆ°æœ€æ–°ï¼‰
    for i in range(1, STAT_LOG_MAX_DAYS + 1):
        if str(i) not in data:
            continue
        entry = data[str(i)]
        entry_date = datetime.strptime(entry["date"], "%Y-%m-%d").date()
        days_ago = (today - entry_date).days
        label = f"{days_ago}å¤©å‰" if days_ago > 0 else "ä»Šå¤©"
        lines.append(
            f"{entry_date.month}æœˆ{entry_date.day}æ—¥({label})ï¼šäººæ•°{entry['users']}ï¼Œè°ƒç”¨æ¬¡æ•°{entry['calls']}"
        )
    return "\n".join(lines)